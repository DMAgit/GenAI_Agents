{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8376f449a4cd31",
   "metadata": {},
   "source": [
    "**TITLE:** MULTI-AGENT INTERVIEWING SYSTEM\n",
    "\n",
    "**DEVELOPERS:**\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b669f9e2849047b",
   "metadata": {},
   "source": [
    "# Setup Instructions for Jupyter Notebook\n",
    "\n",
    "This notebook installs essential packages for working with LangChain, OpenAI, and other data handling tools. \n",
    "\n",
    "### Important Notes:\n",
    "- **Google Colab Users**: If you are using Google Colab, ensure to install `google-colab` specific packages. \n",
    "- **GPU Configuration**: If using Google Colab, you can enable GPU for faster performance by going to:\n",
    "  - **Runtime** > **Change runtime type** > **Hardware accelerator** and selecting **GPU**.\n",
    "  \n",
    "---\n",
    "\n",
    "## Step 1: Install General Utilities and Google Colab Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install general utilities and widgets\n",
    "%pip install pandas opendatasets nest_asyncio ipywebrtc ipywidgets IPython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64043e93ef176632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if using google-colab, else skip it\n",
    "%pip install google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde274d17b4b8f27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Install OpenAI, LangChain, and Related Tools\n",
    "These packages are necessary for using OpenAI’s language models and LangChain's toolkit for search, document processing, and data handling.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ffe9a8e044bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI and related LangChain tools\n",
    "%pip install openai langchain_openai\n",
    "\n",
    "# LangChain Community Tools for search and document handling\n",
    "%pip install langchain_community\n",
    "\n",
    "# Typing extensions and Pydantic\n",
    "%pip install typing_extensions pydantic\n",
    "\n",
    "# LangGraph and experimental LangChain tools\n",
    "%pip install langgraph langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For agent tools\n",
    "%pip install pypdf wikipedia duckduckgo-search playwright\n",
    "\n",
    "!playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963bbc30c8307592",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Database Utilities, SQLAlchemy, and FAISS for Vector Storage\n",
    "\n",
    "- **Database Utilities**: Install SQLAlchemy for database interactions.\n",
    "- **FAISS**: Choose `faiss-cpu` for CPU environments or `faiss-gpu` if you've enabled GPU support on Colab.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888251935ea6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database utilities and SQLAlchemy\n",
    "%pip install SQLAlchemy\n",
    "\n",
    "# FAISS for vector storage and retrieval\n",
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!where python\n",
    "!pip show playwright\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa27fcb72b8e53e",
   "metadata": {},
   "source": [
    "## General Imports\n",
    "This cell includes the essential imports needed to use LangChain, OpenAI, and other data handling tools in any Jupyter Notebook or Python environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d741d4caeeda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for data handling, display, and LangChain functionality\n",
    "import os\n",
    "import opendatasets as od\n",
    "import nest_asyncio\n",
    "\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain and related tools\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# LangChain Agents and supporting libraries\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, Literal, Sequence, List\n",
    "import functools\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6e32631d8416c",
   "metadata": {},
   "source": [
    "## Google Colab Specific Imports\n",
    "This cell should be run only if you're using Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33c03e419f01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab specific imports\n",
    "from google.colab import output\n",
    "from google.colab import userdata\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70f69fdf69c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41518f1fbffb425c",
   "metadata": {},
   "source": [
    "# Get API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c49167463ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Google Colab\n",
    "try:\n",
    "    # Retrieve API key from Google Colab userdata (if stored there)\n",
    "    open_ai_api_key = userdata.get('OPENAI_API_KEY')\n",
    "except:\n",
    "    # Not running on Google Colab; prompt for API key input or retrieve from environment variables\n",
    "    open_ai_api_key = os.getenv('OPENAI_API_KEY') or input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Set the API key as an environment variable for universal access within the notebook\n",
    "os.environ['OPENAI_API_KEY'] = open_ai_api_key\n",
    "\n",
    "# Confirm setup\n",
    "if open_ai_api_key:\n",
    "    print(f\"API key successfully set: {open_ai_api_key}\")\n",
    "else:\n",
    "    print(\"API key not set. Please check your setup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3bc41d2c30b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: \n",
    "# Need to have an alternative that grabs a HuggingFace API key and interfaces with free models there (Llama-3-8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a360a1929e585",
   "metadata": {},
   "source": [
    "# Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241141af1e856401",
   "metadata": {},
   "source": [
    "## 1. Speech-to-text\n",
    "\n",
    "This tool allows the user to record speech and converts it to a text using OpenAI Whisper model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e18d7b5333b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7ad06af747527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a614597653bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_audio_recorder():\n",
    "    camera = CameraStream(constraints={'audio': True, 'video': False})\n",
    "    recorder = AudioRecorder(stream=camera)\n",
    "    display(recorder)\n",
    "    return recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b682f5e34981ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recording(recorder):\n",
    "    audio_data = recorder.audio.value\n",
    "    if audio_data:\n",
    "        with open(\"recording.webm\", \"wb\") as f:\n",
    "            f.write(audio_data)\n",
    "        return \"recording.webm\"\n",
    "    else:\n",
    "        print(\"No audio data was captured. Please try again.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8005ca2b61e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(input_filename, output_filename=\"my_recording.wav\"):\n",
    "    if input_filename and os.path.exists(input_filename):\n",
    "        os.system(f\"ffmpeg -i {input_filename} -ac 1 -f wav {output_filename} -y -hide_banner -loglevel panic\")\n",
    "        if os.path.exists(output_filename):\n",
    "            return output_filename\n",
    "        else:\n",
    "            print(\"Conversion failed.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Input file does not exist.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d27fc546946d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(filename):\n",
    "    with open(filename, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    print(\"\")\n",
    "    print(\"Transcription:\", transcription.text)\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0a312a15ebfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_transcribe_candidate_answer():\n",
    "    \"\"\"Record and transcribe a candidate's answer on interviewers' questions.\"\"\"\n",
    "    # Set up the recorder\n",
    "    recorder = setup_audio_recorder()\n",
    "\n",
    "    # Create a save button\n",
    "    print(\"\")\n",
    "    save_button = widgets.Button(description=\"Save Recording\")\n",
    "\n",
    "    # This dictionary will store the transcribed text\n",
    "    transcription_result = {}\n",
    "\n",
    "    # Define the callback function for the save button\n",
    "    def on_save_clicked(button):\n",
    "        # Save the recording\n",
    "        webm_file = save_recording(recorder)\n",
    "        if webm_file:\n",
    "            # Convert to wav format\n",
    "            wav_file = convert_to_wav(webm_file)\n",
    "            if wav_file:\n",
    "                # Transcribe the audio and store the result\n",
    "                transcription_result['text'] = transcribe_audio(wav_file)\n",
    "\n",
    "    save_button.on_click(on_save_clicked)\n",
    "    display(save_button)\n",
    "\n",
    "    # Return the transcription result dictionary\n",
    "    return transcription_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca99386ecd3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# Try to do live transcription, rather than recording a file. \n",
    "# Take a look at https://gist.github.com/Vaibhavs10/a48d141534cc8d877937d421bb828d8e\n",
    "# and https://github.com/VRSEN/langchain-agents-tutorial/blob/main/main.py\n",
    "\n",
    "# FOSS alternative pipeline, that doesn't rely on OpenAI models\n",
    "# Using HF free API instead \n",
    "# Something like https://github.com/nyrahealth/CrisperWhisper?tab=readme-ov-file#31-usage-with--transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d2e5e97f917bb",
   "metadata": {},
   "source": [
    "## 2. Text Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f961638c01d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_text_input():\n",
    "    text_input = widgets.Textarea(\n",
    "        placeholder=\"Type your answer here...\",\n",
    "        description=\"Answer:\",\n",
    "        layout=widgets.Layout(width='500px', height='100px')\n",
    "    )\n",
    "    display(text_input)\n",
    "    return text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bc16915c6f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_text_input(text_widget):\n",
    "    user_text = text_widget.value\n",
    "    if user_text.strip():\n",
    "        print(\"\\nInput:\\n\", user_text)\n",
    "        return user_text\n",
    "    else:\n",
    "        print(\"No input was provided. Please type your answer and try again.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091dca5fa15aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_submit_text():\n",
    "    \"\"\"Record a candidate's text answer on interviewers' questions which require written output like code.\"\"\"\n",
    "    # Set up the text input widget\n",
    "    text_widget = setup_text_input()\n",
    "\n",
    "    # Create a submit button\n",
    "    print(\"\")\n",
    "    submit_button = widgets.Button(description=\"Save Answer\")\n",
    "\n",
    "    # This variable will store the submitted text\n",
    "    submission_result = {}\n",
    "\n",
    "    # Define the callback function for the submit button\n",
    "    def on_submit_clicked(button):\n",
    "        # Capture the user's text input and store it in the dictionary\n",
    "        submission_result['text'] = submit_text_input(text_widget)\n",
    "\n",
    "    submit_button.on_click(on_submit_clicked)\n",
    "    display(submit_button)\n",
    "\n",
    "    # Wait for user input to be submitted\n",
    "    return submission_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f0fd76213961e",
   "metadata": {},
   "source": [
    "## 3. CV Reader\n",
    "\n",
    "CV Reader for PDF and DOCX files.\n",
    "\n",
    "Instead of CV you can upload your LinkedIn profile extract, which can be exported in a PDF format.\n",
    "\n",
    "This tools can be easily changed to any file reading service, e.g., Azure DI, LlamaParse, custom parsing with PyPdf, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63b534771d50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab version\n",
    "\n",
    "def upload_and_filter_file():\n",
    "    # Upload a single file\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # Check if only one file was uploaded\n",
    "    if len(uploaded) != 1:\n",
    "        print(\"Please upload exactly one file.\")\n",
    "        return None\n",
    "\n",
    "    # Get the uploaded file name and data\n",
    "    file_name, file_data = next(iter(uploaded.items()))\n",
    "\n",
    "    # Check if the file is .pdf or .docx\n",
    "    if not file_name.endswith(('.pdf', '.docx')):\n",
    "        print(\"Invalid file type. Please upload only .pdf or .docx files.\")\n",
    "        return None\n",
    "\n",
    "    # Save the file directly to the /content/ directory\n",
    "    file_path = f'/content/{file_name}'\n",
    "\n",
    "    return file_path\n",
    "\n",
    "cv_file_path = upload_and_filter_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a536813081d7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local jupyter notebook\n",
    "\n",
    "cv_file_path = r'C:\\Users\\DMA\\Downloads\\CV - 2024-1.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a65c074428d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9266679f8fa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_retriever(file_path, k):\n",
    "    pages = []\n",
    "\n",
    "    if file_path.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type.\")\n",
    "\n",
    "    for page in loader.load():\n",
    "        pages.append(page)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63f50b2351bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_retriever = create_cv_retriever(cv_file_path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b754be1121566a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tool = create_retriever_tool(\n",
    "    cv_retriever,\n",
    "    \"search_candidate_info\",\n",
    "    \"Searches and returns candidate's profile with experience, education, and skills.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b580af1e74d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: \n",
    "# Free alternative for embeddings that doesn't use OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18422b0153a965fd",
   "metadata": {},
   "source": [
    "## 4. Hiring Company Info Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411db1436669cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(query):\n",
    "    \"\"\"Fetches content from Wikipedia based on a query.\"\"\"\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    wikipedia_content = wikipedia.run(query)\n",
    "    return wikipedia_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c94cc9e174acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_websites_links(query):\n",
    "    \"\"\"Fetches a list of website links based on a search query using DuckDuckGo.\"\"\"\n",
    "    search = DuckDuckGoSearchResults(output_format=\"list\")\n",
    "    search_results = search.invoke(query)\n",
    "    return [result[\"link\"] for result in search_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138048ef56616c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_websites_content(websites):\n",
    "    \"\"\"Loads the HTML content of a list of websites.\"\"\"\n",
    "    content_list = []\n",
    "    for website in websites:\n",
    "        loader = AsyncChromiumLoader([website])\n",
    "        html_content = loader.load()\n",
    "        content_list.append(html_content)\n",
    "    return content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61832d87cfa91b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_html_content(html_content_list, tags = [\"span\", \"p\", \"b\", \"h3\", \"h4\"]):\n",
    "    \"\"\"Transforms HTML content to extract specific tags using BeautifulSoup.\"\"\"\n",
    "    transformed_content = []\n",
    "    bs_transformer = BeautifulSoupTransformer()\n",
    "    for html in html_content_list:\n",
    "        docs_transformed = bs_transformer.transform_documents(html, tags_to_extract=tags)\n",
    "        for doc in docs_transformed:\n",
    "            transformed_content.append(doc.page_content)\n",
    "    return transformed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e031bd1b42305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_content(query):\n",
    "    \"\"\"Main function to gather content from Wikipedia and websites based on a query.\"\"\"\n",
    "    content = []\n",
    "\n",
    "    wikipedia_content = get_wikipedia_content(query)\n",
    "    content.append(wikipedia_content)\n",
    "\n",
    "    website_links = get_websites_links(f\"What is {query}?\")\n",
    "\n",
    "    html_content_list = load_websites_content(website_links)\n",
    "\n",
    "    transformed_content = transform_html_content(html_content_list)\n",
    "\n",
    "    content.extend(transformed_content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32851a57d96f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Deloitte Company\"\n",
    "websites_content = get_web_content(query)\n",
    "websites_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392099cca9bc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_company_info_retriever(websites_content, k):\n",
    "    docs = []\n",
    "\n",
    "    for website_content in websites_content:\n",
    "        doc = Document(page_content=website_content)\n",
    "        docs.append(doc)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()  # need a FOSS alternative\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2feee0d40acb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info_retriever = create_company_info_retriever(websites_content, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d378d450302799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: update this tool so it gets correct data, this is copied from the cv\n",
    "\n",
    "company_info_tool = create_retriever_tool(\n",
    "    company_info_retriever,\n",
    "    \"search_company_info\",\n",
    "    \"Searches and returns company's profile with company's details to be considered by HR Specialist.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d716952ac5020",
   "metadata": {},
   "source": [
    "## 5. Querying a Dataset\n",
    "\n",
    "This is an optional tool for enhancing the process of hard skills review.\n",
    "\n",
    "The dataset can be changed depending on the needs of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada19680d80eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"https://www.kaggle.com/datasets/syedmharis/software-engineering-interview-questions-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c587555228f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_ds(dataset_url):\n",
    "    od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59829e5ba10feda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "\n",
    "# Set the file path to the downloaded data and the encoding of the file\n",
    "file_path = r\"C:\\Users\\DMA\\Downloads\\Software Questions.csv\"\n",
    "encoding = \"ISO-8859-1\"  # default English encoding\n",
    "\n",
    "loader = CSVLoader(file_path=file_path, encoding=encoding)\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba42e05d275965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text splitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f67d516dc51406",
   "metadata": {},
   "source": [
    "### 5.1a Using OpenAI Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fec19fe82b517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_questions_dataset_retriever(texts, k):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c013344d9c5a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_questions_dataset_retriever(texts=texts, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d590160f25aa77e",
   "metadata": {},
   "source": [
    "### 5.1b Using HuggingFace Embeddings \n",
    "\n",
    "To represent each chunk as a high-dimensional vector, we’ll use Hugging Face's pre-trained model sentence-transformers/all-MiniLM-L6-v2. This model is efficient and well-suited for generating text embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84977845029fc567",
   "metadata": {},
   "source": [
    "We’ll define a simple helper class to handle embedding generation using the Hugging Face model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dca7934bf6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class HuggingFaceEmbeddings:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        # Load the model and tokenizer from Hugging Face\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_texts(self, texts):\n",
    "        # Generate embeddings for each text\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "        return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ce16f9cfb72df",
   "metadata": {},
   "source": [
    "Now, let’s generate embeddings for each of the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897a69ec2ff2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "embeddings_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# Generate embeddings for each chunk of text\n",
    "embeddings = embeddings_model.embed_texts([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eff59bdd058320",
   "metadata": {},
   "source": [
    "After this step, `embeddings` will contain a vector representation of each document chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663811a7f4974e2",
   "metadata": {},
   "source": [
    "To make our embeddings searchable, we’ll use FAISS to create an index. This allows us to find the most similar embeddings to any query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62481f0456eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Initialize the FAISS index\n",
    "embedding_dim = embeddings.shape[1]  # Dimension of embeddings\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Add the embeddings to the FAISS index\n",
    "faiss_index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6a9124bc25b62",
   "metadata": {},
   "source": [
    "Finally, we’ll define a `retriever` function that, given a query, will embed it and retrieve the most similar document chunks from the FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d84f1e759c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(query, texts, embeddings_model, faiss_index, k=5):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embeddings_model.embed_texts([query])[0]\n",
    "    \n",
    "    # Search FAISS index for the top-k similar chunks\n",
    "    distances, indices = faiss_index.search(np.array([query_embedding]), k)\n",
    "    \n",
    "    # Retrieve the corresponding text chunks\n",
    "    results = [texts[i].page_content for i in indices[0]]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498063ba154aff57",
   "metadata": {},
   "source": [
    "For testing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d35189e601810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query\n",
    "query = \"What is the topic of interest?\"\n",
    "\n",
    "# Call the retriever with the required arguments\n",
    "results = retriever(query, texts, embeddings_model, faiss_index, k=5)\n",
    "\n",
    "# Print the top results\n",
    "print(\"Top similar chunks:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9fc77f1caaec8",
   "metadata": {},
   "source": [
    "### 5.2 Define the tool for agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae193c12d94107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: update this tool so its usable by agents\n",
    "\n",
    "@tool\n",
    "questions_database_tool = create_retriever_tool(\n",
    "    create_questions_dataset_retriever,\n",
    "    \"search_subject_matter_questions\",\n",
    "    \"Searches and returns subject matter questions for checking hard skills.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367d4aa565d2239",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Initialize Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32abecc57086fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# Need to test this with OAI key\n",
    "# Test each of the tools are working\n",
    "\n",
    "# Create LangGraph agents, give them roles, assign interactions and tools to each\n",
    "\n",
    "# Implement user-agent interaction\n",
    "# LangGraph - https://github.com/langchain-ai/langgraph/blob/main/docs/docs/how-tos/human_in_the_loop/wait-user-input.ipynb\n",
    "\n",
    "# Add a FOSS alternative for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968cd86c5123092",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\")  # need a FOSS alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfe73049656d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_input_form_with_return():\n",
    "    # Capture inputs\n",
    "    print(\"Invoice input\")\n",
    "    print(\"\")\n",
    "    voice_input = record_and_transcribe_candidate_answer()\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Text input\")\n",
    "    print(\"\")\n",
    "    written_input = record_and_submit_text()\n",
    "\n",
    "    # Define what happens on submit\n",
    "    def on_submit(button):\n",
    "        clear_output()\n",
    "        print(\"Submitted successfully. Moving to the next step...\")\n",
    "\n",
    "    # Create the submit button and link to the on_submit action\n",
    "    print(\"\")\n",
    "    print(\"================================================\")\n",
    "    print(\"Please, click submit button to send your answers\")\n",
    "    print(\"\")\n",
    "    submit_button = widgets.Button(description=\"Submit\")\n",
    "    submit_button.on_click(on_submit)\n",
    "\n",
    "    display(submit_button)\n",
    "\n",
    "    if submit_button:\n",
    "      return voice_input, written_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87f94dee3d8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice, text_input = display_input_form_with_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ce6ff531f8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = f\"Answer: {voice.get('text', '') if voice else ''}\\n\\n{text_input.get('text', '') if text_input else ''}\"\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1956a344b297ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5c6dc75a09db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242afbd93da45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7780cecfc20472",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8c4f051218be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\"type\": \"user\", \"content\": answer}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1784f90bf83fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\"type\": \"user\", \"content\": answer}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fb910",
   "metadata": {},
   "source": [
    "# 3. Agents (DMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedfdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0365ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\")  # need a FOSS alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a844d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going \"bind\" all tools to the model\n",
    "# We have the ACTUAL tools from above, but we also need a mock tool to ask a human\n",
    "# Since `bind_tools` takes in tools but also just tool definitions,\n",
    "# We can define a tool definition for `ask_human`\n",
    "class AskHuman(BaseModel):\n",
    "    \"\"\"Ask the human a question\"\"\"\n",
    "\n",
    "    question: str\n",
    "  \n",
    "llm = llm.bind_tools(tools + [AskHuman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda97721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # If tool call is asking Human, we return that node\n",
    "    # You could also add logic here to let some system know that there's something that requires Human input\n",
    "    # For example, send a slack message, etc\n",
    "    elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n",
    "        return \"ask_human\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad90dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that calls the llm\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10819a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a fake node to ask the human\n",
    "def ask_human(state):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e59fe",
   "metadata": {},
   "source": [
    "Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda63a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the three nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "workflow.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed74746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # We may ask the human\n",
    "        \"ask_human\": \"ask_human\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc918237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# After we get back the human response, we go back to the agent\n",
    "workflow.add_edge(\"ask_human\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a47d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f70d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "# We add a breakpoint BEFORE the `ask_human` node so it never executes\n",
    "app = workflow.compile(checkpointer=memory, interrupt_before=[\"ask_human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(\n",
    "    content=\"Ask the user where they are\"\n",
    ")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_id = app.get_state(config).values[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "tool_message = [ToolMessage(tool_call_id=tool_call_id, content=\"san francisco\")]\n",
    "\n",
    "# We now update the state\n",
    "# Notice that we are also specifying `as_node=\"ask_human\"`\n",
    "# This will apply this update as this node,\n",
    "# which will make it so that afterwards it continues as normal\n",
    "app.update_state(config, {\"messages\": tool_message}, as_node=\"ask_human\")\n",
    "\n",
    "# We can check the state\n",
    "# We can see that the state currently has the `agent` node next\n",
    "# This is based on how we define our graph,\n",
    "# where after the `ask_human` node goes (which we just triggered)\n",
    "# there is an edge to the `agent` node\n",
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(None, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the current state of the application\n",
    "state = app.get_state(config).values\n",
    "\n",
    "# Access the list of messages from the state\n",
    "messages = state[\"messages\"]\n",
    "\n",
    "# Iterate through each message and print its content\n",
    "for message in messages:\n",
    "    print(f\"{message.type.capitalize()} Message: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30a1b0",
   "metadata": {},
   "source": [
    "## 3.1. Define Agents & Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3468408",
   "metadata": {},
   "source": [
    "### 3.1.1. Define Base Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name: str, role: str, skills: List[str], llm):\n",
    "        \"\"\"\n",
    "        Base class for an agent.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name of the agent.\n",
    "            role (str): The role of the agent (e.g., HR, Manager, etc.).\n",
    "            skills (List[str]): The list of skills the agent possesses.\n",
    "            llm: A language model instance for generating responses.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.skills = skills\n",
    "        self.llm = llm\n",
    "\n",
    "    def process_task(self, task: str, context: Optional[List[Dict[str, str]]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Process a task assigned to the agent.\n",
    "\n",
    "        Args:\n",
    "            task (str): The task or question to process.\n",
    "            context (Optional[List[Dict[str, str]]]): Additional context for the task.\n",
    "\n",
    "        Returns:\n",
    "            str: The agent's response.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"You are {self.name}, a {self.role}. Your skills include: {', '.join(self.skills)}. Respond to the task based on your role and skills.\")\n",
    "        ]\n",
    "        \n",
    "        # Include provided context\n",
    "        if context:\n",
    "            for msg in context:\n",
    "                if msg['role'] == 'human':\n",
    "                    messages.append(HumanMessage(content=msg['content']))\n",
    "                elif msg['role'] == 'ai':\n",
    "                    messages.append(AIMessage(content=msg['content']))\n",
    "        \n",
    "        # Add the task as the final input\n",
    "        messages.append(HumanMessage(content=task))\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a2414",
   "metadata": {},
   "source": [
    "### 3.1.1. Define Orchestrator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent(Agent):\n",
    "    def __init__(self, name: str, role: str, skills: List[str], llm):\n",
    "        super().__init__(name, role, skills, llm)\n",
    "\n",
    "    def generate_scenario(self, job_description: str, company_info: str, candidate_cv: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate a scenario for the interview based on input data.\n",
    "\n",
    "        Args:\n",
    "            job_description (str): The job description.\n",
    "            company_info (str): Information about the company.\n",
    "            candidate_cv (str): The candidate's CV.\n",
    "\n",
    "        Returns:\n",
    "            Dict: A structured interview scenario.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Analyze the job description, company information, and candidate CV to generate an interview scenario. \"\n",
    "            \"Include priorities, suggested questions, and areas to focus on.\"\n",
    "        )\n",
    "        context = [\n",
    "            {\"role\": \"human\", \"content\": f\"Job Description: {job_description}\"},\n",
    "            {\"role\": \"human\", \"content\": f\"Company Info: {company_info}\"},\n",
    "            {\"role\": \"human\", \"content\": f\"Candidate CV: {candidate_cv}\"}\n",
    "        ]\n",
    "        response = self.process_task(task, context)\n",
    "        return response  # This should return a structured JSON or text output\n",
    "\n",
    "    def assign_tasks(self, graph, scenario: Dict):\n",
    "        \"\"\"\n",
    "        Assign tasks to other agents based on the generated scenario.\n",
    "\n",
    "        Args:\n",
    "            graph: LangGraph graph instance.\n",
    "            scenario (Dict): The structured interview scenario.\n",
    "        \"\"\"\n",
    "        # Extract priorities from the scenario\n",
    "        for agent_task in scenario.get(\"agents\", []):\n",
    "            agent_name = agent_task[\"role\"]\n",
    "            task = agent_task[\"tasks\"]\n",
    "            \n",
    "            # Dynamically find the corresponding agent node\n",
    "            agent_node = graph.get_node(agent_name)\n",
    "            if agent_node:\n",
    "                graph.add_edge(self, agent_node, task=task)\n",
    "\n",
    "    def process_feedback(self, feedback: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Process feedback from agents to synthesize a final report.\n",
    "\n",
    "        Args:\n",
    "            feedback (Dict): Feedback data from agents.\n",
    "\n",
    "        Returns:\n",
    "            str: A synthesized report on the candidate.\n",
    "        \"\"\"\n",
    "        task = \"Synthesize the following feedback into a unified candidate assessment report.\"\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Feedback: {feedback}\"}]\n",
    "        return self.process_task(task, context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d408a5",
   "metadata": {},
   "source": [
    "### 3.1.2. Define HR Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanResourcesAgent(Agent):\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the Human Resources Agent with specific skills.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=\"Jessica Taylor\",\n",
    "            role=\"Human Resources Specialist\",\n",
    "            skills=[\n",
    "                \"Sourcing Candidates\",\n",
    "                \"Screening Resumes\",\n",
    "                \"Interviewing Techniques\",\n",
    "                \"Candidate Assessment\",\n",
    "                \"Offer Negotiation\",\n",
    "                \"Reference Checking\",\n",
    "                \"Talent Pool Development\",\n",
    "                \"Job Description Writing\",\n",
    "                \"Onboarding Coordination\",\n",
    "                \"Effective Communication\",\n",
    "                \"Active Listening\",\n",
    "                \"Empathy and Rapport Building\",\n",
    "                \"Persuasion and Influence\",\n",
    "            ],\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "    def generate_behavioral_questions(self, job_description: str, company_values: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generate a list of behavioral questions based on the job description and company values.\n",
    "\n",
    "        Args:\n",
    "            job_description (str): The job description.\n",
    "            company_values (str): The company's core values.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of behavioral interview questions.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Generate behavioral interview questions tailored to the following job description \"\n",
    "            \"and company values. Focus on assessing adaptability, teamwork, and problem-solving skills.\"\n",
    "        )\n",
    "        context = [\n",
    "            {\"role\": \"human\", \"content\": f\"Job Description: {job_description}\"},\n",
    "            {\"role\": \"human\", \"content\": f\"Company Values: {company_values}\"}\n",
    "        ]\n",
    "        response = self.process_task(task, context)\n",
    "        return response.split(\"\\n\")  # Assuming questions are returned as a newline-separated string\n",
    "\n",
    "    def ensure_compliance(self, questions: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Check the list of questions for compliance with non-discrimination policies.\n",
    "\n",
    "        Args:\n",
    "            questions (List[str]): The list of interview questions.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A filtered list of compliant questions.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Review the following list of interview questions for compliance with \"\n",
    "            \"non-discrimination policies. Remove or revise any questions that could be biased.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Questions: {', '.join(questions)}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response.split(\"\\n\")\n",
    "\n",
    "    def generate_interview_agenda(self, role_requirements: str, company_info: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a structured interview agenda based on the role requirements and company information.\n",
    "\n",
    "        Args:\n",
    "            role_requirements (str): The role requirements.\n",
    "            company_info (str): Information about the company.\n",
    "\n",
    "        Returns:\n",
    "            str: A detailed interview agenda.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Create a structured interview agenda for the role described below. Include time allocations \"\n",
    "            \"for introductions, behavioral questions, technical questions, and a Q&A session.\"\n",
    "        )\n",
    "        context = [\n",
    "            {\"role\": \"human\", \"content\": f\"Role Requirements: {role_requirements}\"},\n",
    "            {\"role\": \"human\", \"content\": f\"Company Information: {company_info}\"}\n",
    "        ]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e9519",
   "metadata": {},
   "source": [
    "### 3.1.3. Define Manager Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManagerAgent(Agent):\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the Hiring Manager Agent with specific skills.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=\"Michael Brown\",\n",
    "            role=\"Hiring Manager\",\n",
    "            skills=[\n",
    "                # Core Hiring and Candidate Assessment Skills\n",
    "                \"Interviewing Techniques\",\n",
    "                \"Candidate Evaluation\",\n",
    "                \"Behavioral Assessment\",\n",
    "                \"Decision-Making\",\n",
    "                \"Reference Checking\",\n",
    "                # Soft Skills\n",
    "                \"Effective Communication\",\n",
    "                \"Active Listening\",\n",
    "                \"Empathy and Rapport Building\",\n",
    "                \"Time Management\",\n",
    "                # Technical Skills\n",
    "                \"Proficiency in Applicant Tracking Systems (ATS)\",\n",
    "                \"Data-Driven Hiring Decisions\"\n",
    "            ],\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "    def assess_cultural_fit(self, candidate_answers: str, company_values: str) -> str:\n",
    "        \"\"\"\n",
    "        Assess the candidate's cultural fit based on their answers and the company's values.\n",
    "\n",
    "        Args:\n",
    "            candidate_answers (str): Candidate's responses to cultural fit questions.\n",
    "            company_values (str): The company's core values.\n",
    "\n",
    "        Returns:\n",
    "            str: An evaluation of the candidate's cultural fit.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Based on the following candidate responses, evaluate how well they align with \"\n",
    "            \"the company's core values.\"\n",
    "        )\n",
    "        context = [\n",
    "            {\"role\": \"human\", \"content\": f\"Candidate Answers: {candidate_answers}\"},\n",
    "            {\"role\": \"human\", \"content\": f\"Company Values: {company_values}\"}\n",
    "        ]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n",
    "\n",
    "    def evaluate_leadership_potential(self, scenario_response: str) -> str:\n",
    "        \"\"\"\n",
    "        Evaluate the candidate's leadership potential based on their response to a scenario.\n",
    "\n",
    "        Args:\n",
    "            scenario_response (str): The candidate's response to a leadership scenario.\n",
    "\n",
    "        Returns:\n",
    "            str: An assessment of the candidate's leadership potential.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Evaluate the candidate's leadership potential based on their response to the following scenario. \"\n",
    "            \"Focus on their decision-making, problem-solving, and ability to inspire others.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Scenario Response: {scenario_response}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n",
    "\n",
    "    def make_data_driven_decision(self, candidate_metrics: Dict[str, float]) -> str:\n",
    "        \"\"\"\n",
    "        Make a hiring recommendation based on candidate metrics.\n",
    "\n",
    "        Args:\n",
    "            candidate_metrics (Dict[str, float]): A dictionary of candidate metrics (e.g., skills, experience, cultural fit).\n",
    "\n",
    "        Returns:\n",
    "            str: A hiring recommendation.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Based on the following candidate metrics, make a data-driven recommendation on whether to move forward with this candidate.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Candidate Metrics: {candidate_metrics}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n",
    "\n",
    "    def summarize_interview_feedback(self, feedback: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"\n",
    "        Summarize feedback from multiple interviewers into a cohesive report.\n",
    "\n",
    "        Args:\n",
    "            feedback (List[Dict[str, str]]): A list of feedback dictionaries from other interviewers.\n",
    "\n",
    "        Returns:\n",
    "            str: A cohesive summary of the feedback.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Summarize the feedback from the following interviewers into a cohesive report. \"\n",
    "            \"Highlight the candidate's strengths, weaknesses, and overall fit for the role.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Feedback: {feedback}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c496116",
   "metadata": {},
   "source": [
    "### 3.1.4. Define Field Specialist Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622e6bf",
   "metadata": {},
   "source": [
    "Would be cool to have the specific role and skills be generated depending on the field wrt the interview, maybe from another agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldSpecialistAgent(Agent):\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the Field Specialist Agent with specific skills.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=\"Emily Johnson\",\n",
    "            role=\"Field Specialist\",\n",
    "            skills=[\n",
    "                # Core Technical and Functional Skills\n",
    "                \"Technical Expertise in Field Operations\",\n",
    "                \"Problem-Solving in Real-Time Scenarios\",\n",
    "                \"Data Collection and Reporting\",\n",
    "                \"Equipment Handling and Maintenance\",\n",
    "                \"Compliance with Safety Standards\",\n",
    "                # Collaboration and Teamwork\n",
    "                \"Team Coordination\",\n",
    "                \"Effective Communication\",\n",
    "                \"Adaptability\",\n",
    "                \"Conflict Resolution\",\n",
    "                # Technical Skills\n",
    "                \"Proficiency in Field-Specific Software\",\n",
    "                \"Report Writing and Documentation\"\n",
    "            ],\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "    def generate_technical_questions(self, role_specific_requirements: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generate technical questions based on role-specific requirements.\n",
    "\n",
    "        Args:\n",
    "            role_specific_requirements (str): The technical skills and responsibilities of the role.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of technical interview questions.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Create a list of technical questions tailored to the following role-specific requirements. \"\n",
    "            \"Focus on assessing the candidate's expertise in practical, field-specific scenarios.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Role Requirements: {role_specific_requirements}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response.split(\"\\n\")  # Assuming questions are returned as a newline-separated string\n",
    "\n",
    "    def simulate_real_world_scenario(self, scenario_description: str) -> str:\n",
    "        \"\"\"\n",
    "        Simulate a real-world scenario and provide the candidate with a task to solve.\n",
    "\n",
    "        Args:\n",
    "            scenario_description (str): A description of the real-world scenario.\n",
    "\n",
    "        Returns:\n",
    "            str: A description of the simulated task for the candidate.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Design a real-world scenario based on the description below. Provide a detailed task for the candidate to solve, \"\n",
    "            \"focusing on their problem-solving skills and adaptability.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Scenario Description: {scenario_description}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n",
    "\n",
    "    def evaluate_adaptability(self, candidate_response: str) -> str:\n",
    "        \"\"\"\n",
    "        Evaluate the candidate's adaptability based on their response to a scenario.\n",
    "\n",
    "        Args:\n",
    "            candidate_response (str): The candidate's response to a field-specific scenario.\n",
    "\n",
    "        Returns:\n",
    "            str: An evaluation of the candidate's adaptability.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Evaluate the candidate's adaptability based on their response to the following field-specific scenario. \"\n",
    "            \"Focus on their ability to adjust to unexpected changes and find effective solutions.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Candidate Response: {candidate_response}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n",
    "\n",
    "    def review_certifications(self, certifications: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Review and validate the candidate's certifications for the role.\n",
    "\n",
    "        Args:\n",
    "            certifications (List[str]): A list of the candidate's certifications.\n",
    "\n",
    "        Returns:\n",
    "            str: An assessment of the relevance and validity of the certifications.\n",
    "        \"\"\"\n",
    "        task = (\n",
    "            \"Review the following certifications to determine their relevance and validity for the role. \"\n",
    "            \"Provide feedback on their applicability to the field.\"\n",
    "        )\n",
    "        context = [{\"role\": \"human\", \"content\": f\"Certifications: {', '.join(certifications)}\"}]\n",
    "        response = self.process_task(task, context)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9b59e",
   "metadata": {},
   "source": [
    "## Example workflow:\n",
    "\n",
    "### Scenario Overview\n",
    "\n",
    "#### Job Description:\n",
    "\"Senior Field Operations Engineer responsible for managing industrial equipment, leading on-site teams, and troubleshooting hydraulic and mechanical systems under tight deadlines.\"\n",
    "\n",
    "#### Company Values:\n",
    "\"Innovation, Teamwork, Adaptability.\"\n",
    "\n",
    "#### Candidate's Background:\n",
    "* Experience: 8 years in field operations.\n",
    "* Skills: Troubleshooting mechanical systems, team leadership, safety compliance.\n",
    "* Certifications: Certified Field Technician, OSHA Safety Certification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680aa30",
   "metadata": {},
   "source": [
    "### Initiate agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16157af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = OrchestratorAgent(\n",
    "    name=\"Orchestrator\",\n",
    "    role=\"Coordinator\",\n",
    "    skills=[\"Scenario Planning\", \"Task Delegation\", \"Feedback Synthesis\"],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "hr_agent = HumanResourcesAgent(llm)\n",
    "manager_agent = ManagerAgent(llm)\n",
    "field_specialist_agent = FieldSpecialistAgent(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3377fd",
   "metadata": {},
   "source": [
    "### Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e034a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow graph\n",
    "workflow = StateGraph(MessagesState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes (Tasks)\n",
    "def collect_candidate_details(state):\n",
    "    job_description = state.get(\"job_description\", \"Senior Software Engineer for backend development.\")\n",
    "    company_info = state.get(\"company_info\", \"TechCorp values innovation, collaboration, and customer focus.\")\n",
    "    candidate_cv = state.get(\"candidate_cv\", \"Experienced backend engineer with Python and cloud expertise.\")\n",
    "    return {\"job_description\": job_description, \"company_info\": company_info, \"candidate_cv\": candidate_cv}\n",
    "\n",
    "def orchestrator_generate_scenario(state):\n",
    "    scenario = orchestrator.generate_scenario(\n",
    "        state[\"job_description\"], state[\"company_info\"], state[\"candidate_cv\"]\n",
    "    )\n",
    "    return {\"scenario\": scenario}\n",
    "\n",
    "def hr_generate_questions(state):\n",
    "    behavioral_questions = hr_agent.generate_behavioral_questions(\n",
    "        state[\"job_description\"], state[\"company_info\"]\n",
    "    )\n",
    "    return {\"behavioral_questions\": behavioral_questions}\n",
    "\n",
    "def manager_evaluate_candidate(state):\n",
    "    cultural_fit = manager_agent.assess_cultural_fit(\n",
    "        candidate_answers=\"I believe in open communication and teamwork.\",\n",
    "        company_values=state[\"company_info\"],\n",
    "    )\n",
    "    leadership_potential = manager_agent.evaluate_leadership_potential(\n",
    "        scenario_response=\"I prioritize clear delegation and support team members during challenges.\"\n",
    "    )\n",
    "    return {\"cultural_fit\": cultural_fit, \"leadership_potential\": leadership_potential}\n",
    "\n",
    "def field_specialist_tasks(state):\n",
    "    technical_questions = field_specialist_agent.generate_technical_questions(\n",
    "        role_specific_requirements=state[\"job_description\"]\n",
    "    )\n",
    "    adaptability_evaluation = field_specialist_agent.evaluate_adaptability(\n",
    "        candidate_response=\"I inspected system pressure levels and found obstructions in valves.\"\n",
    "    )\n",
    "    return {\n",
    "        \"technical_questions\": technical_questions,\n",
    "        \"adaptability_evaluation\": adaptability_evaluation,\n",
    "    }\n",
    "\n",
    "def orchestrator_synthesize_feedback(state):\n",
    "    feedback = {\n",
    "        \"HR Feedback\": state.get(\"behavioral_questions\"),\n",
    "        \"Manager Feedback\": {\n",
    "            \"Cultural Fit\": state.get(\"cultural_fit\"),\n",
    "            \"Leadership Potential\": state.get(\"leadership_potential\"),\n",
    "        },\n",
    "        \"Field Specialist Feedback\": {\n",
    "            \"Technical Questions\": state.get(\"technical_questions\"),\n",
    "            \"Adaptability Evaluation\": state.get(\"adaptability_evaluation\"),\n",
    "        },\n",
    "    }\n",
    "    final_report = orchestrator.process_feedback(feedback)\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49116e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow.add_node(\"collect_candidate_details\", collect_candidate_details)\n",
    "workflow.add_node(\"orchestrator_generate_scenario\", orchestrator_generate_scenario)\n",
    "workflow.add_node(\"hr_generate_questions\", hr_generate_questions)\n",
    "workflow.add_node(\"manager_evaluate_candidate\", manager_evaluate_candidate)\n",
    "workflow.add_node(\"field_specialist_tasks\", field_specialist_tasks)\n",
    "workflow.add_node(\"orchestrator_synthesize_feedback\", orchestrator_synthesize_feedback)\n",
    "\n",
    "# Define the workflow edges\n",
    "workflow.set_entry_point(\"collect_candidate_details\")\n",
    "workflow.add_edge(\"collect_candidate_details\", \"orchestrator_generate_scenario\")\n",
    "workflow.add_edge(\"orchestrator_generate_scenario\", \"hr_generate_questions\")\n",
    "workflow.add_edge(\"orchestrator_generate_scenario\", \"manager_evaluate_candidate\")\n",
    "workflow.add_edge(\"orchestrator_generate_scenario\", \"field_specialist_tasks\")\n",
    "workflow.add_edge(\"hr_generate_questions\", \"orchestrator_synthesize_feedback\")\n",
    "workflow.add_edge(\"manager_evaluate_candidate\", \"orchestrator_synthesize_feedback\")\n",
    "workflow.add_edge(\"field_specialist_tasks\", \"orchestrator_synthesize_feedback\")\n",
    "workflow.add_edge(\"orchestrator_synthesize_feedback\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6350435",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example run\n",
    "state = app.run({\n",
    "    \"job_description\": \"Senior Software Engineer for backend development.\",\n",
    "    \"company_info\": \"TechCorp values innovation, collaboration, and customer focus.\",\n",
    "    \"candidate_cv\": \"Experienced backend engineer with Python and cloud expertise.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state[\"final_report\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fa4c8cd964f92",
   "metadata": {},
   "source": [
    "-----\n",
    "# Stretch goal: TTS\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08d9683f86af87",
   "metadata": {},
   "source": [
    "Define model and TTS pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210545fca2c5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the TTS model\n",
    "tts_pipeline = pipeline(\"text-to-speech\", model=\"espnet/kan-bayashi_ljspeech_vits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c26c3dd6ea189",
   "metadata": {},
   "source": [
    "Generate and Play Text with TTS in Real-Time\n",
    "\n",
    "Create a loop where the language model generates text in small chunks. Each chunk will be converted to speech and played immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81c891045e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "def generate_and_play_text(prompt, max_chunks=5, chunk_size=50):\n",
    "    generated_text = \"\"\n",
    "    \n",
    "    # Generate text in chunks\n",
    "    for _ in range(max_chunks):\n",
    "        # Generate a chunk of text\n",
    "        output = text_generator(prompt + generated_text, max_new_tokens=chunk_size, do_sample=True)\n",
    "        new_text = output[0][\"generated_text\"][len(prompt + generated_text):]\n",
    "        \n",
    "        # Append the new text to the generated text\n",
    "        generated_text += new_text\n",
    "        print(new_text)  # Print the generated text chunk\n",
    "\n",
    "        # Generate TTS for the current chunk\n",
    "        audio = tts_pipeline(new_text)\n",
    "\n",
    "        # Autoplay the audio chunk in the notebook\n",
    "        ipd.display(ipd.Audio(audio[\"wav\"], autoplay=True))\n",
    "        \n",
    "        # Add a short delay to simulate real-time generation if needed\n",
    "        # time.sleep(1)  # Uncomment if you want to control the timing\n",
    "\n",
    "# Example usage\n",
    "generate_and_play_text(\"Once upon a time,\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_agents",
   "language": "python",
   "name": "genai_agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
